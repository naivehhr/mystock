# -*- coding: utf-8 -*-
"""
æ’ç”Ÿç§‘æŠ€æŒ‡æ•° (HSTECH) æ™ºèƒ½åˆ†ææ¨¡å—

åŠŸèƒ½æµç¨‹ï¼š
1. ä»ä¸œæ–¹è´¢å¯Œè·å–å®æ—¶è¡Œæƒ…å’Œå†å²æ•°æ®
2. è°ƒç”¨ LLM è¿›è¡Œæ”¯æ’‘ä½ã€å‹åŠ›ä½å’Œå…¥åœºæ—¶æœºåˆ†æ
3. ç”ŸæˆåŒ…å«åˆ†æç»“æœçš„å¯è§†åŒ–å›¾è¡¨
4. æä¾›æ ‡å‡†åŒ–æ¥å£ä¾›æŠ¥å‘Šç”Ÿæˆæ¨¡å—è°ƒç”¨

æ•°æ®æ¥æºï¼šä¸œæ–¹è´¢å¯Œ https://quote.eastmoney.com/gb/zsHSTECH.html
"""

import requests
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime
import sys
import os
import logging
import base64
from io import BytesIO
from typing import Dict, Optional, Tuple
from dataclasses import dataclass

# æ·»åŠ  analyzer ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from ai_analyzer import call_ai
from config import LOG_LEVEL

# ============= æ—¥å¿—é…ç½® =============
logger = logging.getLogger(__name__)
logger.setLevel(LOG_LEVEL)

if not logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(LOG_LEVEL)
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

# ============= é…ç½®å¸¸é‡ =============
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
    "Referer": "https://quote.eastmoney.com/",
}

SECID = "124.HSTECH"  # æ’ç”Ÿç§‘æŠ€æŒ‡æ•°


@dataclass
class MarketData:
    """å¸‚åœºæ•°æ®å°è£…"""
    realtime: Optional[Dict]
    history: Optional[pd.DataFrame]
    ma250: Optional[float] = None
    recent_high: Optional[float] = None
    recent_low: Optional[float] = None


class HSTECHDataFetcher:
    """æ’ç”Ÿç§‘æŠ€æŒ‡æ•°æ•°æ®è·å–å™¨"""
    
    def __init__(self):
        self.secid = SECID
        self.headers = HEADERS
        self.max_retries = 3
    
    def get_realtime_data(self) -> Optional[Dict]:
        """ä»ä¸œæ–¹è´¢å¯Œè·å–å®æ—¶è¡Œæƒ…æ•°æ®"""
        logger.info("å¼€å§‹è·å–æ’ç”Ÿç§‘æŠ€æŒ‡æ•°å®æ—¶è¡Œæƒ…...")
        
        try:
            url = (
                f"https://push2.eastmoney.com/api/qt/stock/get?"
                f"secid={self.secid}&"
                f"fields=f43,f44,f45,f46,f47,f48,f50,f51,f52,f55,f57,f58,f60,f170,f171"
            )
            
            resp = requests.get(url, headers=self.headers, timeout=10)
            resp.raise_for_status()
            data = resp.json()
            
            if data.get("data"):
                d = data["data"]
                realtime_data = {
                    "åç§°": "æ’ç”Ÿç§‘æŠ€æŒ‡æ•°",
                    "æœ€æ–°ä»·": d.get("f43", 0) / 100,
                    "æ¶¨è·Œå¹…": d.get("f170", 0) / 100,
                    "æ¶¨è·Œé¢": d.get("f171", 0) / 100,
                    "ä»Šå¼€": d.get("f46", 0) / 100,
                    "æœ€é«˜": d.get("f44", 0) / 100,
                    "æœ€ä½": d.get("f45", 0) / 100,
                    "æ˜¨æ”¶": d.get("f60", 0) / 100,
                    "æˆäº¤é‡": d.get("f47", 0),
                    "æˆäº¤é¢": d.get("f48", 0),
                }
                logger.info(f"å®æ—¶è¡Œæƒ…è·å–æˆåŠŸ - æœ€æ–°ä»·ï¼š{realtime_data['æœ€æ–°ä»·']:.2f}ç‚¹ï¼Œæ¶¨è·Œå¹…ï¼š{realtime_data['æ¶¨è·Œå¹…']:+.2f}%")
                return realtime_data
            else:
                logger.warning("ä¸œæ–¹è´¢å¯Œ API è¿”å›æ•°æ®ä¸ºç©º")
                return None
                
        except Exception as e:
            logger.error(f"å®æ—¶è¡Œæƒ…è·å–å¤±è´¥ï¼š{e}")
            return None
    
    def get_history_data(self, days: int = 365) -> Optional[pd.DataFrame]:
        """ä»ä¸œæ–¹è´¢å¯Œè·å–å†å² K çº¿æ•°æ®"""
        logger.info(f"å¼€å§‹è·å–æ’ç”Ÿç§‘æŠ€æŒ‡æ•°å†å²æ•°æ®ï¼ˆ{days}å¤©ï¼‰...")
        
        for attempt in range(self.max_retries):
            try:
                url = (
                    f"https://push2his.eastmoney.com/api/qt/stock/kline/get?"
                    f"secid={self.secid}&fields1=f1,f2,f3,f4,f5,f6&"
                    f"fields2=f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61&"
                    f"klt=101&fqt=1&end=20500101&lmt={days + 10}"
                )
                
                resp = requests.get(url, headers=self.headers, timeout=20)
                resp.raise_for_status()
                data = resp.json()
                
                if data.get("data") and data["data"].get("klines"):
                    klines = data["data"]["klines"]
                    records = []
                    for line in klines:
                        parts = line.split(",")
                        records.append({
                            "æ—¥æœŸ": parts[0],
                            "å¼€ç›˜": float(parts[1]),
                            "æ”¶ç›˜": float(parts[2]),
                            "æœ€é«˜": float(parts[3]),
                            "æœ€ä½": float(parts[4]),
                            "æˆäº¤é‡": float(parts[5]),
                            "æˆäº¤é¢": float(parts[6]),
                        })
                    
                    df = pd.DataFrame(records)
                    df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
                    df.set_index("æ—¥æœŸ", inplace=True)
                    
                    logger.info(f"å†å²æ•°æ®è·å–æˆåŠŸ - å…±{len(df)}æ¡è®°å½•ï¼Œæ—¶é—´èŒƒå›´ï¼š{df.index[0].strftime('%Y-%m-%d')} è‡³ {df.index[-1].strftime('%Y-%m-%d')}")
                    return df
                else:
                    logger.warning(f"ä¸œæ–¹è´¢å¯Œ API è¿”å›æ•°æ®ä¸ºç©ºï¼Œå°è¯•é‡è¯•... (ç¬¬{attempt + 1}/{self.max_retries}æ¬¡)")
                    if attempt < self.max_retries - 1:
                        import time
                        time.sleep(2)
                        continue
                    return None
                    
            except Exception as e:
                logger.error(f"å†å² K çº¿æ¥å£è·å–å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {e}")
                if attempt < self.max_retries - 1:
                    import time
                    time.sleep(2)
                    continue
        
        logger.error("æš‚æ— æ³•è·å–å†å² K çº¿æ•°æ®ï¼ˆä¸œæ–¹è´¢å¯Œ K çº¿æ¥å£åœ¨å½“å‰ç½‘ç»œç¯å¢ƒä¸‹ä¸å¯ç”¨ï¼‰")
        return None
    
    def calculate_technical_indicators(self, df: pd.DataFrame) -> Tuple[float, float, float]:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼š250 æ—¥å‡çº¿ã€è¿‘ 20 æ—¥é«˜ç‚¹ã€è¿‘ 20 æ—¥ä½ç‚¹"""
        logger.info("è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        
        ma250 = df["æ”¶ç›˜"].rolling(window=250).mean().iloc[-1]
        recent_high = df["æœ€é«˜"].tail(20).max()
        recent_low = df["æœ€ä½"].tail(20).min()
        
        logger.info(f"æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å®Œæˆ - MA250: {ma250:.2f}ç‚¹ï¼Œè¿‘ 20 æ—¥é«˜ç‚¹ï¼š{recent_high:.2f}ç‚¹ï¼Œè¿‘ 20 æ—¥ä½ç‚¹ï¼š{recent_low:.2f}ç‚¹")
        return ma250, recent_high, recent_low


class HSTECHAnalyzer:
    """æ’ç”Ÿç§‘æŠ€æŒ‡æ•° LLM åˆ†æå™¨"""
    
    def __init__(self):
        pass
    
    def analyze(self, realtime_data: Dict, history_data: pd.DataFrame) -> str:
        """è°ƒç”¨ LLM å¯¹æ’ç”Ÿç§‘æŠ€æŒ‡æ•°è¿›è¡Œåˆ†æ"""
        logger.info("å¼€å§‹è°ƒç”¨ LLM è¿›è¡Œæ™ºèƒ½åˆ†æ...")
        
        try:
            latest_close = realtime_data["æœ€æ–°ä»·"]
            change_pct = realtime_data["æ¶¨è·Œå¹…"]
            
            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            recent_high = history_data["æœ€é«˜"].tail(20).max()
            recent_low = history_data["æœ€ä½"].tail(20).min()
            ma250 = history_data["æ”¶ç›˜"].rolling(window=250).mean().iloc[-1]
            
            # å‡†å¤‡åˆ†ææ•°æ®æ‘˜è¦
            data_summary = f"""
æ’ç”Ÿç§‘æŠ€æŒ‡æ•° (124.HSTECH) å®æ—¶æ•°æ®ï¼š
- æœ€æ–°ä»·ï¼š{latest_close:.2f} ç‚¹
- æ¶¨è·Œå¹…ï¼š{change_pct:+.2f}%
- å¼€ç›˜ï¼š{realtime_data['ä»Šå¼€']:.2f} ç‚¹
- æœ€é«˜ï¼š{realtime_data['æœ€é«˜']:.2f} ç‚¹
- æœ€ä½ï¼š{realtime_data['æœ€ä½']:.2f} ç‚¹
- æ˜¨æ”¶ï¼š{realtime_data['æ˜¨æ”¶']:.2f} ç‚¹

æŠ€æœ¯é¢æ•°æ®ï¼š
- è¿‘ 20 æ—¥æœ€é«˜ç‚¹ï¼š{recent_high:.2f} ç‚¹
- è¿‘ 20 æ—¥æœ€ä½ç‚¹ï¼š{recent_low:.2f} ç‚¹
- 250 æ—¥å‡çº¿ï¼š{ma250:.2f} ç‚¹
- å½“å‰ç‚¹ä½ï¼š{latest_close:.2f} ç‚¹
"""
            
            prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„æ¸¯è‚¡å¸‚åœºåˆ†æå¸ˆï¼Œæ“…é•¿æŠ€æœ¯åˆ†æå’Œå®æˆ˜ç­–ç•¥ã€‚è¯·åŸºäºä»¥ä¸‹æ’ç”Ÿç§‘æŠ€æŒ‡æ•° (124.HSTECH) çš„æ•°æ®ï¼Œè¿›è¡Œæ”¯æ’‘ä½å’Œå‹åŠ›ä½åˆ†æï¼Œå¹¶ç»™å‡ºå…¥åœºæ—¶æœºå»ºè®®ï¼š

{data_summary}

åˆ†æè¦æ±‚ï¼š
1. **æ”¯æ’‘ä½åˆ†æ**ï¼šè¯†åˆ«å…³é”®æ”¯æ’‘ä½ï¼ˆè‡³å°‘ 2 ä¸ªï¼‰ï¼Œè¯´æ˜ç†ç”±
2. **å‹åŠ›ä½åˆ†æ**ï¼šè¯†åˆ«å…³é”®å‹åŠ›ä½ï¼ˆè‡³å°‘ 2 ä¸ªï¼‰ï¼Œè¯´æ˜ç†ç”±
3. **å…¥åœºæ—¶æœºå»ºè®®**ï¼šç»™å‡ºå…·ä½“çš„å…¥åœºç‚¹ä½åŒºé—´å’Œæ­¢æŸä½
4. **é£é™©æç¤º**ï¼šç®€è¦æé†’ä¸»è¦é£é™©å› ç´ 

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒå®¢è§‚ä¸“ä¸šï¼Œæ§åˆ¶åœ¨ 300 å­—ä»¥å†…ã€‚ç›´æ¥ç»™å‡ºåˆ†æç»“æœï¼Œä¸éœ€è¦å®¢å¥—è¯ã€‚"""
            
            logger.debug(f"å‘é€æç¤ºè¯åˆ° LLMï¼Œé•¿åº¦ï¼š{len(prompt)}å­—ç¬¦")
            result = call_ai(prompt)
            
            if result:
                logger.info("LLM åˆ†æè°ƒç”¨æˆåŠŸ")
                logger.debug(f"LLM è¿”å›ç»“æœé•¿åº¦ï¼š{len(result)}å­—ç¬¦")
                return result
            else:
                logger.warning("LLM è¿”å›ç»“æœä¸ºç©º")
                return self._generate_fallback_analysis(realtime_data, history_data)
                
        except Exception as e:
            logger.error(f"LLM åˆ†æè°ƒç”¨å¤±è´¥ï¼š{e}")
            return self._generate_fallback_analysis(realtime_data, history_data)
    
    def _generate_fallback_analysis(self, realtime_data: Dict, history_data: pd.DataFrame) -> str:
        """ç”ŸæˆåŸºäºè§„åˆ™çš„æŠ€æœ¯åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        logger.info("ä½¿ç”¨æŠ€æœ¯åˆ†ææ¨¡æ¿ç”Ÿæˆå¤‡ç”¨åˆ†æç»“æœ...")
        
        latest_close = realtime_data["æœ€æ–°ä»·"]
        change_pct = realtime_data["æ¶¨è·Œå¹…"]
        recent_high = history_data["æœ€é«˜"].tail(20).max()
        recent_low = history_data["æœ€ä½"].tail(20).min()
        ma250 = history_data["æ”¶ç›˜"].rolling(window=250).mean().iloc[-1]
        
        aggressive_entry_low = int(latest_close * 0.98)
        aggressive_entry_high = int(latest_close * 0.99)
        steady_entry = int(recent_low)
        stop_loss = int(recent_low * 0.97)
        
        analysis = f"""
**æŠ€æœ¯é¢åˆ†æ**ï¼š
- å½“å‰ç‚¹ä½ï¼š{latest_close:.2f} ç‚¹ï¼Œæ¶¨è·Œå¹… {change_pct:+.2f}%
- è¿‘ 20 æ—¥åŒºé—´ï¼š{recent_low:.2f} - {recent_high:.2f} ç‚¹
- é•¿æœŸè¶‹åŠ¿çº¿ï¼š250 æ—¥å‡çº¿ {ma250:.2f} ç‚¹

**æ”¯æ’‘ä½**ï¼š
1. {recent_low:.0f} ç‚¹ï¼ˆè¿‘ 20 æ—¥ä½ç‚¹ï¼‰
2. {int(ma250):.0f} ç‚¹ï¼ˆ250 æ—¥å‡çº¿ï¼‰

**å‹åŠ›ä½**ï¼š
1. {recent_high:.0f} ç‚¹ï¼ˆè¿‘ 20 æ—¥é«˜ç‚¹ï¼‰
2. {int(recent_high * 1.05):.0f} ç‚¹ï¼ˆå‰æœŸå¹³å°ï¼‰

**æ“ä½œå»ºè®®**ï¼š
- æ¿€è¿›å‹ï¼šå¯åœ¨ {aggressive_entry_low}-{aggressive_entry_high} ç‚¹åŒºé—´è½»ä»“è¯•å¤š
- ç¨³å¥å‹ï¼šç­‰å¾…å›è¸© {steady_entry} ç‚¹é™„è¿‘å†è€ƒè™‘å…¥åœº
- æ­¢æŸä½ï¼š{stop_loss} ç‚¹

*æ³¨ï¼šæ­¤åˆ†æåŸºäºè§„åˆ™æ¨¡æ¿ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚*
"""
        logger.info("å¤‡ç”¨åˆ†æç»“æœç”ŸæˆæˆåŠŸ")
        return analysis


class HSTECHChartGenerator:
    """æ’ç”Ÿç§‘æŠ€æŒ‡æ•°å›¾è¡¨ç”Ÿæˆå™¨"""
    
    def __init__(self):
        pass
    
    def generate_analysis_chart(
        self,
        history_data: pd.DataFrame,
        realtime_data: Dict,
        llm_analysis: str,
        output_path: Optional[str] = None,
        return_base64: bool = True
    ) -> Tuple[Optional[str], Optional[str]]:
        """ç”ŸæˆæŠ€æœ¯åˆ†æå›¾è¡¨ï¼ˆä»… K çº¿å›¾å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼‰
        
        Args:
            history_data: å†å²æ•°æ®
            realtime_data: å®æ—¶æ•°æ®
            llm_analysis: LLM åˆ†æç»“æœ
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆNone åˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
            return_base64: æ˜¯å¦è¿”å› Base64 ç¼–ç ï¼ˆé»˜è®¤ Trueï¼‰
            
        Returns:
            (file_path, base64_data) å…ƒç»„
        """
        logger.info("å¼€å§‹ç”ŸæˆæŠ€æœ¯åˆ†æå›¾è¡¨...")
        
        try:
            # æå–å…³é”®æ•°æ®
            latest_close = realtime_data["æœ€æ–°ä»·"]
            ma250 = history_data["æ”¶ç›˜"].rolling(window=250).mean().iloc[-1]
            recent_high = history_data["æœ€é«˜"].tail(20).max()
            recent_low = history_data["æœ€ä½"].tail(20).min()
            
            # è®¡ç®—å…¥åœºç‚¹ä½
            aggressive_entry_low = int(recent_low * 0.98)
            aggressive_entry_high = int(recent_low * 0.99)
            steady_entry = int(recent_low)
            stop_loss = int(recent_low * 0.97)
            
            # åˆ›å»ºå›¾è¡¨ï¼ˆä¿æŒåŸå§‹å¸ƒå±€ï¼‰
            fig, ax1 = plt.subplots(figsize=(16, 8))
            
            # ===== ä¸ŠåŠéƒ¨åˆ†ï¼šK çº¿å›¾å’ŒæŠ€æœ¯æŒ‡æ ‡ =====
            ax1.plot(history_data.index, history_data["æ”¶ç›˜"], label="æ”¶ç›˜ä»·", color="blue", linewidth=1.5)
            ax1.plot(history_data.index, history_data["MA250"], label="250 æ—¥å‡çº¿", color="orange", linewidth=1.5, alpha=0.7)
            
            # æ ‡è®°å…³é”®ä½ç½®
            ax1.axhline(y=recent_low, color="green", linestyle="--", linewidth=2, label=f"æ”¯æ’‘ä½ï¼š{recent_low:.0f}ç‚¹")
            ax1.axhline(y=recent_high, color="red", linestyle="--", linewidth=2, label=f"å‹åŠ›ä½ï¼š{recent_high:.0f}ç‚¹")
            
            # å¡«å……äº¤æ˜“åŒºé—´
            ax1.fill_between(history_data.index, recent_low, recent_high, alpha=0.15, color="gray", label="è¿‘ 20 æ—¥äº¤æ˜“åŒºé—´")
            
            # æ ‡è®°å…¥åœºç‚¹ä½
            ax1.axhline(y=aggressive_entry_low, color="purple", linestyle=":", linewidth=1.5, label=f"æ¿€è¿›å…¥åœºä¸‹é™ï¼š{aggressive_entry_low}")
            ax1.axhline(y=aggressive_entry_high, color="purple", linestyle=":", linewidth=1.5, label=f"æ¿€è¿›å…¥åœºä¸Šé™ï¼š{aggressive_entry_high}")
            ax1.axhline(y=steady_entry, color="cyan", linestyle="-.", linewidth=1.5, label=f"ç¨³å¥å…¥åœºä½ï¼š{steady_entry}")
            ax1.axhline(y=stop_loss, color="black", linestyle=":", linewidth=1, label=f"æ­¢æŸä½ï¼š{stop_loss}")
            
            # å¡«å……æ¿€è¿›å…¥åœºåŒºé—´
            ax1.fill_between(history_data.index, aggressive_entry_low, aggressive_entry_high, alpha=0.15, color="purple", label="æ¿€è¿›å…¥åœºåŒºé—´")
            
            # å½“å‰ä»·ä½æ ‡è®°
            ax1.axhspan(latest_close - 10, latest_close + 10, alpha=0.2, color="blue", label=f"å½“å‰ä»·ä½ï¼š{latest_close:.0f}")
            
            ax1.set_title("æ’ç”Ÿç§‘æŠ€æŒ‡æ•° (HSTECH) - æŠ€æœ¯åˆ†æå›¾", fontsize=16, fontweight='bold')
            ax1.set_xlabel("æ—¥æœŸ", fontsize=12)
            ax1.set_ylabel("æŒ‡æ•°ç‚¹ä½", fontsize=12)
            ax1.legend(loc="upper left", bbox_to_anchor=(0.98, 0.98), ncol=1, fontsize=9)
            ax1.grid(True, alpha=0.3)
            
            # æ·»åŠ æ ‡é¢˜
            fig.suptitle(
                f"æ’ç”Ÿç§‘æŠ€æŒ‡æ•°æ™ºèƒ½åˆ†ææŠ¥å‘Š - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                fontsize=18,
                fontweight='bold',
                y=0.995
            )
            
            plt.tight_layout(rect=[0, 0, 1, 0.96])
            
            # ä¿å­˜å›¾ç‰‡åˆ°æ–‡ä»¶
            file_path = None
            if output_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                output_path = os.path.join(
                    os.path.dirname(os.path.dirname(os.path.abspath(__file__))),
                    "reports",
                    f"hstech_chart_{timestamp}.png"
                )
            
            plt.savefig(output_path, dpi=150, bbox_inches='tight')
            logger.info(f"æŠ€æœ¯åˆ†æå›¾è¡¨ä¿å­˜æˆåŠŸï¼š{output_path}")
            file_path = output_path
            
            # è½¬æ¢ä¸º Base64
            base64_data = None
            if return_base64:
                buf = BytesIO()
                plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
                buf.seek(0)
                img_bytes = buf.read()
                base64_data = base64.b64encode(img_bytes).decode('utf-8')
                logger.info("å›¾ç‰‡å·²è½¬æ¢ä¸º Base64 ç¼–ç ")
            
            plt.close()
            return file_path, base64_data
            
        except Exception as e:
            logger.error(f"å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼š{e}")
            raise


class HSTECHAnalyzerFacade:
    """æ’ç”Ÿç§‘æŠ€æŒ‡æ•°åˆ†æå¤–è§‚ç±» - æä¾›ç»Ÿä¸€çš„å¯¹å¤–æ¥å£"""
    
    def __init__(self):
        self.data_fetcher = HSTECHDataFetcher()
        self.analyzer = HSTECHAnalyzer()
        self.chart_generator = HSTECHChartGenerator()
    
    def generate_full_report(self, save_chart: bool = True, verbose: bool = False) -> Dict:
        """
        ç”Ÿæˆå®Œæ•´çš„æ’ç”Ÿç§‘æŠ€æŒ‡æ•°åˆ†ææŠ¥å‘Š
        
        Args:
            save_chart: æ˜¯å¦ä¿å­˜åˆ†æå›¾è¡¨
            verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—ï¼ˆé»˜è®¤ Falseï¼Œåªåœ¨ç³»ç»Ÿè°ƒç”¨æ—¶è¾“å‡ºå…³é”®ä¿¡æ¯ï¼‰
            
        Returns:
            åŒ…å«æ‰€æœ‰åˆ†æç»“æœçš„å­—å…¸
        """
        if verbose:
            logger.info("=" * 60)
            logger.info("å¼€å§‹ç”Ÿæˆæ’ç”Ÿç§‘æŠ€æŒ‡æ•°å®Œæ•´åˆ†ææŠ¥å‘Š")
            logger.info("=" * 60)
        else:
            logger.info("æ­£åœ¨ç”Ÿæˆæ’ç”Ÿç§‘æŠ€æŒ‡æ•°åˆ†ææŠ¥å‘Š...")
        
        try:
            # Step 1: è·å–å®æ—¶è¡Œæƒ…æ•°æ®
            realtime_data = self.data_fetcher.get_realtime_data()
            if not realtime_data:
                logger.error("å®æ—¶è¡Œæƒ…æ•°æ®è·å–å¤±è´¥")
                raise ValueError("æ— æ³•è·å–å®æ—¶è¡Œæƒ…æ•°æ®")
            
            # Step 2: è·å–å†å²æ•°æ®
            history_data = self.data_fetcher.get_history_data(days=365)
            if history_data is None or history_data.empty:
                logger.error("å†å²æ•°æ®è·å–å¤±è´¥")
                raise ValueError("æ— æ³•è·å–å†å²æ•°æ®")
            
            # Step 3: è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            ma250, recent_high, recent_low = self.data_fetcher.calculate_technical_indicators(history_data)
            history_data["MA250"] = history_data["æ”¶ç›˜"].rolling(window=250).mean()
            
            # Step 4: è°ƒç”¨ LLM è¿›è¡Œåˆ†æ
            llm_analysis = self.analyzer.analyze(realtime_data, history_data)
            
            # Step 5: ç”Ÿæˆåˆ†æå›¾è¡¨ï¼ˆåŒæ—¶è·å–æ–‡ä»¶è·¯å¾„å’Œ Base64ï¼‰
            chart_path = None
            chart_base64 = None
            if save_chart:
                chart_path, chart_base64 = self.chart_generator.generate_analysis_chart(
                    history_data=history_data,
                    realtime_data=realtime_data,
                    llm_analysis=llm_analysis,
                    return_base64=True
                )
            
            # ç»„è£…å®Œæ•´æŠ¥å‘Š
            report = {
                "realtime_data": realtime_data,
                "history_data": history_data,
                "technical_indicators": {
                    "ma250": ma250,
                    "recent_high": recent_high,
                    "recent_low": recent_low,
                },
                "llm_analysis": llm_analysis,
                "chart_path": chart_path,  # æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºå­˜æ¡£ï¼‰
                "chart_base64": chart_base64,  # Base64 ç¼–ç ï¼ˆç”¨äºé‚®ä»¶ï¼‰
                "timestamp": datetime.now().isoformat(),
            }
            
            if verbose:
                logger.info("æ’ç”Ÿç§‘æŠ€æŒ‡æ•°å®Œæ•´åˆ†ææŠ¥å‘Šç”ŸæˆæˆåŠŸ")
                logger.info("=" * 60)
            else:
                logger.info(f"æŠ¥å‘Šç”Ÿæˆå®Œæˆ - å›¾è¡¨ï¼š{chart_path}")
            
            return report
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå®Œæ•´æŠ¥å‘Šå¤±è´¥ï¼š{e}")
            raise
    
    def get_quick_analysis(self) -> str:
        """
        å¿«é€Ÿè·å–åˆ†æç»“æœï¼ˆä»…æ–‡å­—åˆ†æï¼Œä¸ç”Ÿæˆå›¾è¡¨ï¼‰
        
        Returns:
            LLM åˆ†æç»“æœå­—ç¬¦ä¸²
        """
        logger.info("å¼€å§‹å¿«é€Ÿè·å–åˆ†æç»“æœ...")
        
        try:
            # è·å–æ•°æ®
            realtime_data = self.data_fetcher.get_realtime_data()
            if not realtime_data:
                # ä½¿ç”¨å†å²æ•°æ®çš„æœ€æ–°å€¼
                history_data = self.data_fetcher.get_history_data(days=5)
                if history_data is None or history_data.empty:
                    raise ValueError("æ— æ³•è·å–ä»»ä½•æ•°æ®")
                
                realtime_data = {
                    "åç§°": "æ’ç”Ÿç§‘æŠ€æŒ‡æ•°",
                    "æœ€æ–°ä»·": history_data["æ”¶ç›˜"].iloc[-1],
                    "æ¶¨è·Œå¹…": 0.0,
                    "ä»Šå¼€": history_data["å¼€ç›˜"].iloc[-1],
                    "æœ€é«˜": history_data["æœ€é«˜"].iloc[-1],
                    "æœ€ä½": history_data["æœ€ä½"].iloc[-1],
                    "æ˜¨æ”¶": history_data["æ”¶ç›˜"].iloc[-2] if len(history_data) > 1 else history_data["æ”¶ç›˜"].iloc[-1],
                }
            
            history_data = self.data_fetcher.get_history_data(days=365)
            if history_data is None or history_data.empty:
                history_data = self.data_fetcher.get_history_data(days=30)
            
            # è°ƒç”¨ LLM åˆ†æ
            analysis = self.analyzer.analyze(realtime_data, history_data)
            
            logger.info("å¿«é€Ÿè·å–åˆ†æç»“æœå®Œæˆ")
            return analysis
            
        except Exception as e:
            logger.error(f"å¿«é€Ÿè·å–åˆ†æå¤±è´¥ï¼š{e}")
            raise


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå®Œæ•´åˆ†ææµç¨‹"""
    try:
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = HSTECHAnalyzerFacade()
        
        # ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼ˆä½¿ç”¨ verbose=True æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼‰
        report = analyzer.generate_full_report(save_chart=True, verbose=True)
        
        # æ‰“å°æŠ¥å‘Šæ‘˜è¦
        print("\n" + "=" * 60)
        print("ğŸ“Š æ’ç”Ÿç§‘æŠ€æŒ‡æ•°åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        
        realtime = report["realtime_data"]
        print(f"\nã€å®æ—¶è¡Œæƒ…ã€‘")
        print(f"  æœ€æ–°ä»·ï¼š{realtime['æœ€æ–°ä»·']:.2f} ç‚¹")
        print(f"  æ¶¨è·Œå¹…ï¼š{realtime['æ¶¨è·Œå¹…']:+.2f}%")
        print(f"  æˆäº¤é‡ï¼š{realtime['æˆäº¤é‡']} æ‰‹")
        
        tech = report["technical_indicators"]
        print(f"\nã€æŠ€æœ¯æŒ‡æ ‡ã€‘")
        print(f"  250 æ—¥å‡çº¿ï¼š{tech['ma250']:.2f} ç‚¹")
        print(f"  è¿‘ 20 æ—¥é«˜ç‚¹ï¼š{tech['recent_high']:.2f} ç‚¹")
        print(f"  è¿‘ 20 æ—¥ä½ç‚¹ï¼š{tech['recent_low']:.2f} ç‚¹")
        
        print(f"\nã€LLM åˆ†æç»“æœã€‘")
        print(report["llm_analysis"])
        
        if report["chart_path"]:
            print(f"\nã€åˆ†æå›¾è¡¨ã€‘å·²ä¿å­˜è‡³ï¼š{report['chart_path']}")
        if report.get("chart_base64"):
            base64_len = len(report["chart_base64"])
            print(f"ã€Base64 æ•°æ®ã€‘é•¿åº¦ï¼š{base64} å­—ç¬¦ï¼ˆå¯ç”¨äºé‚®ä»¶åµŒå…¥ï¼‰")
        
        print("=" * 60)
        
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
